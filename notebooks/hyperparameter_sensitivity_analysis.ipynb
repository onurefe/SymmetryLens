{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 23:17:49.983448: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-22 23:17:50.108711: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-22 23:17:50.137964: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-22 23:17:50.742690: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/envs/tf_gpu_py310/lib:\n",
      "2025-02-22 23:17:50.742746: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/envs/tf_gpu_py310/lib:\n",
      "2025-02-22 23:17:50.742751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from symmetry_lens import *\n",
    "from os.path import join\n",
    "from os import makedirs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVING_DIR = \"model_weights_sensitivity_analysis\"\n",
    "NUM_TRAINING_EPOCHS = 2500\n",
    "BATCH_SIZE = 630\n",
    "OUTPUT_REPRESENTATION = \"natural\"\n",
    "SYNTHETIC_DATASET_FEATURES = [\n",
    "    {\n",
    "        \"type\": \"gaussian\",\n",
    "        \"scale_min\": 0.2,\n",
    "        \"scale_max\": 1.0,\n",
    "        \"amplitude_min\": 0.5,\n",
    "        \"amplitude_max\": 1.5\n",
    "    }\n",
    "]\n",
    "NOISE_STD = 0.05\n",
    "WAVEFORM_TIMESTEPS=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model to train.\n",
    "model = create_model(zero_padding_size=WAVEFORM_TIMESTEPS,\n",
    "                     use_zero_padding=True,\n",
    "                     num_uniformity_scales=1,\n",
    "                     conditional_probability_estimator_hidden_layer_size = 112)\n",
    "\n",
    "# Create model and load weights.\n",
    "x_init = np.random.normal(size=(BATCH_SIZE, WAVEFORM_TIMESTEPS, 1))\n",
    "model = create_model(zero_padding_size=WAVEFORM_TIMESTEPS,\n",
    "                     use_zero_padding=True,\n",
    "                     conditional_probability_estimator_hidden_layer_size = 112,\n",
    "                     num_uniformity_scales=1)\n",
    "model.compile()\n",
    "model(x_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_cosine_similarity_to_unit_shift(learned_gen):\n",
    "    rotate_1 = np.roll(np.eye(WAVEFORM_TIMESTEPS), shift=1, axis=1)\n",
    "    rotate_2 = np.roll(np.eye(WAVEFORM_TIMESTEPS), shift=-1, axis=1)\n",
    "    \n",
    "    vl = np.reshape(learned_gen, newshape=[WAVEFORM_TIMESTEPS*WAVEFORM_TIMESTEPS])\n",
    "    v1 = np.reshape(rotate_1, newshape=[WAVEFORM_TIMESTEPS*WAVEFORM_TIMESTEPS])\n",
    "    v2 = np.reshape(rotate_2, newshape=[WAVEFORM_TIMESTEPS*WAVEFORM_TIMESTEPS])\n",
    "    \n",
    "    c1 = vl * v1 / (np.linalg.norm(vl) * np.linalg.norm(v1)) \n",
    "    c2 = vl * v2 / (np.linalg.norm(vl) * np.linalg.norm(v2))\n",
    "    \n",
    "    return np.maximum(c1, c2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeroth elements are default parameters.\n",
    "estimator_lr = [2.5e-3, 2.0e-3, 3.0e-3]\n",
    "model_lr = [2.5e-4, 2.0e-4, 3.0e-4]\n",
    "lr_decay = [0.1, 0.08, 0.12]\n",
    "alignment = [1., 0.8, 1.2]\n",
    "uniformity = [1., 0.8, 1.2]\n",
    "resolution = [1., 0.8, 1.2]\n",
    "infomax = [1., 0.8, 1.2]\n",
    "\n",
    "params = zip(estimator_lr, \n",
    "             model_lr, \n",
    "             lr_decay, \n",
    "             alignment, \n",
    "             uniformity, \n",
    "             resolution, \n",
    "             infomax)\n",
    "\n",
    "hyperparams = {\"estimator_lr\":estimator_lr, \n",
    "               \"model_lr\":model_lr, \n",
    "               \"lr_decay\":lr_decay, \n",
    "               \"alignment\":alignment, \n",
    "               \"uniformity\":uniformity, \n",
    "               \"resolution\":resolution, \n",
    "               \"infomax\":infomax}\n",
    "\n",
    "scores = {\"estimator_lr\":[], \n",
    "          \"model_lr\":[], \n",
    "          \"lr_decay\":[], \n",
    "          \"alignment\":[], \n",
    "          \"uniformity\":[], \n",
    "          \"resolution\":[], \n",
    "          \"infomax\":[]}\n",
    "\n",
    "default_experiment = True\n",
    "\n",
    "for key in list(hyperparams.keys()):\n",
    "    # Set default parameter values.\n",
    "    exp_hyperparams = {\"estimator_lr\":estimator_lr[0], \n",
    "                       \"model_lr\":model_lr[0],\n",
    "                       \"lr_decay\":lr_decay[0],\n",
    "                       \"alignment\": alignment[0],\n",
    "                       \"uniformity\": uniformity[0],\n",
    "                       \"resolution\": resolution[0],\n",
    "                       \"infomax\": infomax[0]}\n",
    "    \n",
    "    # Currently, it should work but this code is not clean. I guess, I could clean this more.\n",
    "    if default_experiment:\n",
    "        vals = hyperparams[key][:1]\n",
    "    else:\n",
    "        vals = hyperparams[key][1:]\n",
    "        \n",
    "    for val in vals:\n",
    "        exp_hyperparams[key] = val\n",
    "        model_path = join(MODEL_SAVING_DIR, f\"modified:{key}__value:{val}\", f\"ep{NUM_TRAINING_EPOCHS-1}.h5\")\n",
    "        \n",
    "        # At this point the module is loaded. Now, what to do?\n",
    "        model.load_weights(model_path)\n",
    "        score = _compute_cosine_similarity_to_unit_shift(model.symmetry_generator)\n",
    "        \n",
    "        # If this was the first experiment, it's the default one so\n",
    "        if default_experiment:\n",
    "            for _key in list(hyperparams.keys()):\n",
    "                scores[_key].append(score)\n",
    "            \n",
    "            default_experiment = False\n",
    "        else:\n",
    "            scores[key].append(score)        \n",
    "            \n",
    "        # Then, what could I use the scores for? Could calculate local sensitivity. For each of the difference. \n",
    "        #Afterwards, I could select random points and could compute the global one? I guess this could be rather \n",
    "        #difficult. Instead of this, ablation study and local sensitivity analysis must suffice. \n",
    "        # Actually, I have four gpus. Then? 8 experiments of this kind could be fit in. Right? However, \n",
    "        #should change it more? Not sure about what should be done at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
